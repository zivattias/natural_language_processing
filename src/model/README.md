Due to Github file size limit, you are asked to download the pre-trained models and unzip them according to the instructions:

`distilbert-base-multilingual-cased` from [here](https://huggingface.co/distilbert/distilbert-base-multilingual-cased), and unzip inside `src/model/information-retrieval/distilbert-base-multilingual-cased`.

`t5-small` from [here](https://huggingface.co/google-t5/t5-small), and unzip inside `src/model/text-summarization`.

`distilbert-base-uncased` from [here](https://huggingface.co/distilbert/distilbert-base-uncased), and unzip inside `src/model/text-classification`